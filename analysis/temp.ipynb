{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, DataCollatorForSeq2Seq\n",
    "from transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "\n",
    "model_name = \"google-t5/t5-base\"\n",
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2cf859e2662456f92245c2b1a4d4001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/home/a/miniforge3/envs/nlp_/lib/python3.8/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
      "/home/a/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ff95648c984e0faf289d8d75d16993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/318 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 13.646711349487305,\n",
       " 'eval_model_preparation_time': 0.0046,\n",
       " 'eval_rouge1': 0.0005002026534695476,\n",
       " 'eval_rouge2': 3.420791571169569e-05,\n",
       " 'eval_rougeL': 0.0005052136288200727,\n",
       " 'eval_rougeLsum': 0.0005057834870835789,\n",
       " 'eval_runtime': 71.5496,\n",
       " 'eval_samples_per_second': 17.764,\n",
       " 'eval_steps_per_second': 4.444}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model = \"google-t5/t5-base\"\n",
    "# model = \"google-bert/bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
    "\n",
    "\n",
    "dataset = Dataset.load_from_disk('reduced_dataset')\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "dataset_train_test_val = dataset.train_test_split(test_size=0.2)\n",
    "dataset_test_val = dataset_train_test_val['test'].train_test_split(test_size=0.5)\n",
    "train_data = dataset_train_test_val['train']\n",
    "dev_data = dataset_test_val['train']\n",
    "test_data = dataset_test_val['test']\n",
    "\n",
    "\n",
    "\n",
    "prefix = \"answer the question: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "    # The \"inputs\" are the tokenized answer:\n",
    "    inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "    \n",
    "    # The \"labels\" are the tokenized outputs:\n",
    "    labels = tokenizer(text_target=examples[\"answer\"], max_length=512, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Set up Rouge score for evaluation\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "test_data = test_data.map(preprocess_function, batched=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "# Set up trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=dev_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model = \"openai-community/gpt2\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07df4485f1694bc09b8e1c96394f7416",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1271 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'max_length'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 62\u001b[0m\n\u001b[1;32m     58\u001b[0m data_collator \u001b[38;5;241m=\u001b[39m DataCollatorForSeq2Seq(tokenizer\u001b[38;5;241m=\u001b[39mtokenizer, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[1;32m     60\u001b[0m test_data \u001b[38;5;241m=\u001b[39m test_data\u001b[38;5;241m.\u001b[39mmap(preprocess_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 62\u001b[0m training_args \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mper_device_eval_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpush_to_hub\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m54\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Increase max_length to accommodate the input sequence length\u001b[39;49;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Set up trainer\u001b[39;00m\n\u001b[1;32m     79\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Seq2SeqTrainer(\n\u001b[1;32m     80\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     81\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics\n\u001b[1;32m     87\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'max_length'"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model = \"openai-community/gpt2\"\n",
    "# model = \"google-bert/bert-base-cased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForCausalLM.from_pretrained(model)\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "dataset = Dataset.load_from_disk('reduced_dataset')\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "dataset_train_test_val = dataset.train_test_split(test_size=0.2)\n",
    "dataset_test_val = dataset_train_test_val['test'].train_test_split(test_size=0.5)\n",
    "train_data = dataset_train_test_val['train']\n",
    "dev_data = dataset_test_val['train']\n",
    "test_data = dataset_test_val['test']\n",
    "\n",
    "\n",
    "\n",
    "prefix = \"answer the question: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "    # The \"inputs\" are the tokenized answer:\n",
    "    inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "    \n",
    "    # The \"labels\" are the tokenized outputs:\n",
    "    labels = tokenizer(text_target=examples[\"answer\"], max_length=512, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Set up Rouge score for evaluation\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "test_data = test_data.map(preprocess_function, batched=True)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=4,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    max_length=54,  # Increase max_length to accommodate the input sequence length\n",
    "\n",
    ")\n",
    "\n",
    "# Set up trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=dev_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.evaluate(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bert_model_name = \"google-bert/bert-base-cased\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 13\u001b[0m\n\u001b[1;32m      9\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model)\n\u001b[1;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForSeq2SeqLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model)\n\u001b[0;32m---> 13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241m.\u001b[39mload_from_disk(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreduced_dataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(preprocess_function, batched\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m dataset_train_test_val \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mtrain_test_split(test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "model = \"facebook/bart-base\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
    "\n",
    "\n",
    "dataset = Dataset.load_from_disk('reduced_dataset')\n",
    "dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "dataset_train_test_val = dataset.train_test_split(test_size=0.2)\n",
    "dataset_test_val = dataset_train_test_val['test'].train_test_split(test_size=0.5)\n",
    "train_data = dataset_train_test_val['train']\n",
    "dev_data = dataset_test_val['train']\n",
    "test_data = dataset_test_val['test']\n",
    "\n",
    "\n",
    "\n",
    "prefix = \"answer the question: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "    # The \"inputs\" are the tokenized answer:\n",
    "    inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "    \n",
    "    # The \"labels\" are the tokenized outputs:\n",
    "    labels = tokenizer(text_target=examples[\"answer\"], max_length=512, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Set up Rouge score for evaluation\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"bleu\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "test_data = test_data.map(preprocess_function, batched=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=1000,\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=4,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    use_cpu=True\n",
    ")\n",
    "\n",
    "# Set up trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=dev_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import TrainingArguments\n",
    "import evaluate\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")\n",
    "metric = evaluate.load(\"f1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.load_from_disk('reduced_dataset')\n",
    "dataset_train_test_val = dataset.train_test_split(test_size=0.2)\n",
    "dataset_test_val = dataset_train_test_val['test'].train_test_split(test_size=0.5)\n",
    "train_data = dataset_train_test_val['train']\n",
    "dev_data = dataset_test_val['train']\n",
    "test_data = dataset_test_val['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432c227313214b309c511a23875b36d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "133082999b1a4de99d6931a3914d3bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2542 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "prefix = \"answer the question: \"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n",
    "    # The \"inputs\" are the tokenized answer:\n",
    "    inputs = [prefix + doc for doc in examples[\"question\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=128, truncation=True)\n",
    "    \n",
    "    # The \"labels\" are the tokenized outputs:\n",
    "    labels = tokenizer(text_target=examples[\"answer\"], max_length=512, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Set up Rouge score for evaluation\n",
    "nltk.download(\"punkt\", quiet=True)\n",
    "metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "\n",
    "    # decode preds and labels\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    # rougeLSum expects newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "\n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    return result\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=4,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    push_to_hub=False\n",
    ")\n",
    "\n",
    "# Set up trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "/home/a/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/generation/utils.py:1259: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input length of input_ids is 31, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/trainer_seq2seq.py:180\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix, **gen_kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mgather\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gen_kwargs \u001b[38;5;241m=\u001b[39m gen_kwargs\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/trainer.py:3666\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3663\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3665\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3666\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3667\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3669\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3670\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3676\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3677\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/trainer.py:3857\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3854\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   3856\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 3857\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3858\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3859\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/trainer_seq2seq.py:310\u001b[0m, in \u001b[0;36mSeq2SeqTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys, **gen_kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m generation_inputs\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m==\u001b[39m generation_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    306\u001b[0m ):\n\u001b[1;32m    307\u001b[0m     generation_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    308\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_attention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    309\u001b[0m     }\n\u001b[0;32m--> 310\u001b[0m generated_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgeneration_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;66;03m# Temporary hack to ensure the generation config is not initialized for each iteration of the evaluation loop\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;66;03m# TODO: remove this hack when the legacy code that initializes generation_config from a model config is\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# removed in https://github.com/huggingface/transformers/blob/98d88b23f54e5a23e741833f1e973fdf600cc2c5/src/transformers/generation/utils.py#L1183\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39m_from_model_config:\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_/lib/python3.8/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/generation/utils.py:1839\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1832\u001b[0m         model_kwargs[cache_name] \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1833\u001b[0m             DynamicCache\u001b[38;5;241m.\u001b[39mfrom_legacy_cache(past)\n\u001b[1;32m   1834\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m requires_cross_attention_cache\n\u001b[1;32m   1835\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m EncoderDecoderCache\u001b[38;5;241m.\u001b[39mfrom_legacy_cache(past)\n\u001b[1;32m   1836\u001b[0m         )\n\u001b[1;32m   1837\u001b[0m         use_dynamic_cache_by_default \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1839\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_generated_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_default_max_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;66;03m# 7. determine generation mode\u001b[39;00m\n\u001b[1;32m   1842\u001b[0m generation_mode \u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mget_generation_mode(assistant_model)\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_/lib/python3.8/site-packages/transformers/generation/utils.py:1267\u001b[0m, in \u001b[0;36mGenerationMixin._validate_generated_length\u001b[0;34m(self, generation_config, input_ids_length, has_default_max_length)\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids_length \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m generation_config\u001b[38;5;241m.\u001b[39mmax_length:\n\u001b[1;32m   1266\u001b[0m     input_ids_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder_input_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput length of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_ids_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but `max_length` is set to\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1269\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This can lead to unexpected behavior. You should consider\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1270\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m increasing `max_length` or, better yet, setting `max_new_tokens`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1273\u001b[0m \u001b[38;5;66;03m# 2. Min length warnings due to unfeasible parameter combinations\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m min_length_error_suffix \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1275\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Generation will stop at the defined maximum length. You should decrease the minimum length and/or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1276\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincrease the maximum length.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1277\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Input length of input_ids is 31, but `max_length` is set to 20. This can lead to unexpected behavior. You should consider increasing `max_length` or, better yet, setting `max_new_tokens`."
     ]
    }
   ],
   "source": [
    "trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "type object 'AutoModel' has no attribute 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Get a list of all available models\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m all_models \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m(library\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuggingface/transformers\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print the model names\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m all_models:\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'AutoModel' has no attribute 'list'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "# Get a list of all available models\n",
    "all_models = AutoModel.list(library=\"huggingface/transformers\")\n",
    "\n",
    "# Print the model names\n",
    "for model in all_models:\n",
    "    print(model[\"name\"])\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "# Sample text data\n",
    "text = \"\"\"\n",
    "Python is a versatile programming language.\n",
    "It is used for web development, data analysis, and machine learning.\n",
    "Python has a large community and a rich ecosystem of libraries and frameworks.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the text and calculate word frequencies\n",
    "words = text.lower().split()\n",
    "word_freq = Counter(words)\n",
    "\n",
    "# Get the most common words and their frequencies\n",
    "num_words = 10\n",
    "most_common_words = word_freq.most_common(num_words)\n",
    "\n",
    "# Plot the word frequencies\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(num_words), [freq for word, freq in most_common_words])\n",
    "plt.xlabel(\"Word Rank\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Most Common Words and Their Frequencies\")\n",
    "plt.xticks(range(num_words), [word for word, freq in most_common_words])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It exist a wickedness and stormy nighttime.']\n"
     ]
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "# Create an OcrAug object\n",
    "aug = nac.KeyboardAug()\n",
    "aug = naw.SpellingAug()\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "# Apply OCR augmentation\n",
    "text = \"It was a dark and stormy night.\"\n",
    "augmented_text = aug.augment(text)\n",
    "print(augmented_text)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.binomial(1, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
